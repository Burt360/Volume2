{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, array([1, 0]))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pull(probabilities, payouts, action):\n",
    "    \"\"\"Simulate one pull.\n",
    "    \n",
    "    Return:\n",
    "        payout (float)\n",
    "        state_update (ndarray): [1,0] or [0,1]\n",
    "    \"\"\"\n",
    "\n",
    "    # Sample from Bernoulli\n",
    "    payed = np.random.binomial(1, probabilities[action])\n",
    "\n",
    "    # Return payout, (sucess, failure) pair\n",
    "    return payed * payouts[action], \\\n",
    "        np.array([1,0]) if payed else np.array([0,1])\n",
    "\n",
    "probabilities = np.array([0.2, 0.4, 0.6, 0.8])\n",
    "payouts = np.copy(probabilities[::-1])\n",
    "\n",
    "pull(probabilities, payouts, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17.10(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  3.5       ,  3.5       ,  3.5       ,  3.5       ],\n",
       "       [10.        ,  5.27      ,  3.93333333,  3.5       ,  0.        ],\n",
       "       [10.        ,  6.66666667,  5.        ,  0.        ,  0.        ],\n",
       "       [10.        ,  7.5       ,  0.        ,  0.        ,  0.        ],\n",
       "       [10.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_R(r, M, beta):\n",
    "    \"\"\"Compute values of R(a,b,r) for 1 <= a+b <= M with discount beta.\"\"\"\n",
    "\n",
    "    # Init\n",
    "    R_values = np.zeros((M+1, M+1))\n",
    "\n",
    "    # Each [a, b] entry (one-indexed) contains a+b\n",
    "    index_sums = np.zeros_like(R_values)\n",
    "    A = np.arange(M+1)\n",
    "    B = np.arange(M+1)[:, np.newaxis]\n",
    "    index_sums += A + B\n",
    "    \n",
    "    # Only modify entries where a+b = M\n",
    "    M_mask = (index_sums == M)\n",
    "\n",
    "    # Use equation (17.10) in Volume 2\n",
    "    R_values[M_mask] = np.maximum(A/index_sums[M_mask], r)/(1-beta)\n",
    "    \n",
    "    # Recurse with equation (17.7)\n",
    "    for i in range(1, M):\n",
    "        index_slice = index_sums[:-i, :-i]\n",
    "        index_mask = (index_slice == M-i)\n",
    "        \n",
    "        R_values[:-i, :-i][index_mask] = \\\n",
    "            np.maximum( \\\n",
    "                (\n",
    "                    (\n",
    "                        A[-i-1::-1] * (1 + beta*R_values[A[:-i]+1, :-i]) + \\\n",
    "                        A[:-i]      * (    beta*R_values[:-i, A[:-i]+1])\n",
    "                    ) / (M-i) \\\n",
    "                )[index_mask],\n",
    "                r / (1-beta)\n",
    "            )\n",
    "\n",
    "    return R_values\n",
    "\n",
    "compute_R(0.35, 4, 0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17.10(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4, 100,  16])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gittins(payouts, states, M, K, beta, all_R_values=None):\n",
    "    \"\"\"Compute approximate Gittins index for each arm.\n",
    "\n",
    "    Assume n arms\n",
    "    \n",
    "    Args:\n",
    "        payouts ((n,)-ndarray, dtype float)\n",
    "        states ((n,2)-ndarray, dtype int): [[a1,b1], ..., [an, bn]]\n",
    "        M (int): use for compute_R\n",
    "        K (int): grid size to find r which most nearly approximates\n",
    "                 Gittins index for each arm\n",
    "        beta (float): discount factor\n",
    "        all_R_values: after first run of this function, get all_R_values\n",
    "                      from return and continue using\n",
    "    Return:\n",
    "        index ((n,)-ndarray, dtype float): array of Gittins indices\n",
    "        all_R_values: allow to use again on next call to this function\n",
    "    \"\"\"\n",
    "\n",
    "    # Grid of K possible values of r\n",
    "    r = np.linspace(0, 1, K+1, endpoint=False)[1:]\n",
    "\n",
    "    if all_R_values is None:\n",
    "        # Compute R(a,b,r) for r in R and 1 <= a+b <= M\n",
    "        all_R_values = np.stack(np.vectorize(compute_R, otypes=[np.ndarray])(r, M, beta))\n",
    "    \n",
    "    # Gittins index for each state\n",
    "    indices = -1 * np.ones_like(payouts)\n",
    "\n",
    "    # For each state, find approximate index using equation (17.9)\n",
    "    for i, (a, b) in enumerate(states):\n",
    "        ab = a+b\n",
    "        # If a+b == M, then use a and b rather than a+1 and b+1\n",
    "        if ab >= M:\n",
    "            # If a+b > M, nudge a and b down so that a+b = M\n",
    "            if ab > M:\n",
    "                # If odd difference, nudge a down so even difference\n",
    "                if (ab-M) % 2 == 1:\n",
    "                    a -= 1\n",
    "                \n",
    "                a -= int((ab - M)/2)\n",
    "                b -= int((ab - M)/2)\n",
    "\n",
    "                # If a or b ends up being negative, nudge it up and other down\n",
    "                if a < 0:\n",
    "                    b += a\n",
    "                    a = 0\n",
    "                elif b < 0:\n",
    "                    a += b\n",
    "                    b = 0\n",
    "                    \n",
    "            R_values = all_R_values[:,a,b]\n",
    "            right_side = (1-beta) * (a*(1 + beta*R_values) + b*beta*R_values) / (a+b)\n",
    "            \n",
    "            # Get value of r that minimizes the absolute difference\n",
    "            indices[i] = np.argmin(np.abs(r - right_side))\n",
    "\n",
    "        elif 1 <= a+b < M:\n",
    "            right_side = (1-beta) * \\\n",
    "                    (a*(1 + beta*all_R_values[:,a+1,b]) + b*beta*all_R_values[:,a,b+1]) \\\n",
    "                / (a+b)\n",
    "            \n",
    "            indices[i] = np.argmin(np.abs(r - right_side))\n",
    "\n",
    "    return indices * payouts, all_R_values\n",
    "\n",
    "payouts = np.array([2, 100, 2])\n",
    "states = np.array([[1,4], [4,33], [100,1]])\n",
    "M, K, beta = 100, 9, 0.9\n",
    "gittins(payouts, states, M, K, beta)[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9348809208959215, array([0.2       , 0.33333333, 0.62941176, 0.5       ]))"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulation(probabilities, payouts, K, T, M, beta):\n",
    "    \"\"\"Simulate bandit problem using Gittins index.\n",
    "    \n",
    "    Args:\n",
    "        K (float): 0 < K < 1\n",
    "        T (int): number of iterations\n",
    "        M (int): M > T\n",
    "        beta (float): discount factor\n",
    "    \n",
    "    Return:\n",
    "        total_reward (float)\n",
    "        estimated_probabilities (ndarray)\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(probabilities)\n",
    "\n",
    "    # Init states\n",
    "    states = np.array([[1,1] for _ in range(n)])\n",
    "\n",
    "    # First run\n",
    "    indices, all_R_values = gittins(payouts, states, M, K, beta)\n",
    "    choice = np.argmax(indices)\n",
    "    total_reward, state_update = pull(probabilities, payouts, choice)\n",
    "    states[choice] += state_update\n",
    "\n",
    "    # T-1 runs\n",
    "    for i in range(T-1):\n",
    "\n",
    "        indices, _ = gittins(payouts, states, M, K, beta, all_R_values)\n",
    "        choice = np.argmax(indices)\n",
    "\n",
    "        reward, state_update = pull(probabilities, payouts, choice)\n",
    "\n",
    "        total_reward += beta**i * reward\n",
    "        states[choice] += state_update\n",
    "\n",
    "    # Estimate probabilities\n",
    "    estimated_probabilities = states[:,0] / np.sum(states, axis=1)\n",
    "\n",
    "    return total_reward, estimated_probabilities\n",
    "\n",
    "probabilities = np.array([0.2, 0.4, 0.6, 0.8])\n",
    "payouts = np.copy(probabilities[::-1])\n",
    "T, M, K, beta = 175, 200, 9, 0.9\n",
    "\n",
    "simulation(probabilities, payouts, K, T, M, beta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
