{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient_methods.py\n",
    "\"\"\"Volume 2: Gradient Descent Methods.\n",
    "Nathan Schill\n",
    "Section 2\n",
    "Thurs. Mar. 2, 2023\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy import optimize as opt\n",
    "from scipy import linalg as la\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00538056, 0.00697149, 0.003187  ]), True, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem 1\n",
    "def steepest_descent(f, Df, x0, tol=1e-5, maxiter=100):\n",
    "    \"\"\"Compute the minimizer of f using the exact method of steepest descent.\n",
    "\n",
    "    Parameters:\n",
    "        f (function): The objective function. Accepts a NumPy array of shape\n",
    "            (n,) and returns a float.\n",
    "        Df (function): The first derivative of f. Accepts and returns a NumPy\n",
    "            array of shape (n,).\n",
    "        x0 ((n,) ndarray): The initial guess.\n",
    "        tol (float): The stopping tolerance.\n",
    "        maxiter (int): The maximum number of iterations to compute.\n",
    "\n",
    "    Returns:\n",
    "        ((n,) ndarray): The approximate minimum of f.\n",
    "        (bool): Whether or not the algorithm converged.\n",
    "        (int): The number of iterations computed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Init\n",
    "    converged = False    \n",
    "    xk = x0\n",
    "    dfxk = Df(xk)\n",
    "\n",
    "    for i in range(1, maxiter+1):\n",
    "        # Line search for a\n",
    "        line = lambda a: f(xk - a*dfxk)\n",
    "        ak = opt.minimize_scalar(line).x\n",
    "\n",
    "        # Set next iteration\n",
    "        xk = xk - ak*dfxk\n",
    "\n",
    "        # Compute next derivative; determine if converged\n",
    "        dfxk = Df(xk)\n",
    "        if np.linalg.norm(dfxk, ord=np.inf) < tol:\n",
    "            converged = True\n",
    "            break\n",
    "    \n",
    "    return xk, converged, i\n",
    "\n",
    "def f(t):\n",
    "    x,y,z = t\n",
    "    return x**4 + y**4 + z**4\n",
    "def df(t):\n",
    "    x,y,z = t\n",
    "    return np.array([4*x**3, 4*y**3, 4*z**3])\n",
    "\n",
    "x0 = np.array([1,2,3])\n",
    "steepest_descent(f, df, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.99998513, 0.99997021]), True, 3757)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(t):\n",
    "    x,y = t\n",
    "    return 100*(y - x**2)**2 + (1 - x)**2\n",
    "def df(t):\n",
    "    x,y = t\n",
    "    return np.array([2*100*(y - x**2)*(-2)*x + 2*(1 - x)*(-1),\n",
    "                     2*100*(y - x**2)])\n",
    "\n",
    "x0 = np.array([0.5, 0.5])\n",
    "steepest_descent(f, df, x0, maxiter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2\n",
    "def conjugate_gradient(Q, b, x0, tol=1e-4):\n",
    "    \"\"\"Solve the linear system Qx = b with the conjugate gradient algorithm.\n",
    "\n",
    "    Parameters:\n",
    "        Q ((n,n) ndarray): A positive-definite square matrix.\n",
    "        b ((n, ) ndarray): The right-hand side of the linear system.\n",
    "        x0 ((n,) ndarray): An initial guess for the solution to Qx = b.\n",
    "        tol (float): The convergence tolerance.\n",
    "\n",
    "    Returns:\n",
    "        ((n,) ndarray): The solution to the linear system Qx = b.\n",
    "        (bool): Whether or not the algorithm converged.\n",
    "        (int): The number of iterations computed.\n",
    "    \"\"\"\n",
    "\n",
    "    converged = True\n",
    "    \n",
    "    # Get dimension of space\n",
    "    n = Q.shape[0]\n",
    "\n",
    "    ### Follow Algorithm 12.1 in the lab PDF\n",
    "    xk = x0\n",
    "    rk = Q@x0 - b\n",
    "    dk = -rk\n",
    "\n",
    "    k = 0\n",
    "    while np.linalg.norm(rk) >= tol:\n",
    "        if k >= n:\n",
    "            # Already completed n iterations, so break\n",
    "            converged = False\n",
    "            break\n",
    "        \n",
    "        ak = rk@rk / (dk@Q@dk)\n",
    "        xk = xk + ak*dk\n",
    "        rk1 = rk + ak*Q@dk\n",
    "        bk = rk1@rk1 / (rk@rk)\n",
    "        dk = -rk1 + bk*dk\n",
    "\n",
    "        rk = rk1\n",
    "        k += 1\n",
    "    \n",
    "    return xk, converged, k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.5, 2. ]), True, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = np.array([[2, 0], [0, 4]])\n",
    "b = np.array([1, 8])\n",
    "\n",
    "x0 = np.array([0.6, 3])\n",
    "conjugate_gradient(Q, b, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.50000475, 2.00000057]), True, 7)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(t):\n",
    "    x,y = t\n",
    "    return x**2 + 2*y**2 - x - 8*y\n",
    "def df(t):\n",
    "    x,y = t\n",
    "    return np.array([2*x - 1, 4*y - 8])\n",
    "\n",
    "x0 = np.array([1, 1])\n",
    "steepest_descent(f, df, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Q, b, and the initial guess x0\n",
    "n = 4\n",
    "A = np.random.random((n,n))\n",
    "Q = A.T @ A\n",
    "b, x0 = np.random.random((2,n))\n",
    "x = conjugate_gradient(Q, b, x0)[0]\n",
    "np.allclose(Q @ x, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3\n",
    "def nonlinear_conjugate_gradient(f, df, x0, tol=1e-5, maxiter=100):\n",
    "    \"\"\"Compute the minimizer of f using the nonlinear conjugate gradient\n",
    "    algorithm.\n",
    "\n",
    "    Parameters:\n",
    "        f (function): The objective function. Accepts a NumPy array of shape\n",
    "            (n,) and returns a float.\n",
    "        Df (function): The first derivative of f. Accepts and returns a NumPy\n",
    "            array of shape (n,).\n",
    "        x0 ((n,) ndarray): The initial guess.\n",
    "        tol (float): The stopping tolerance.\n",
    "        maxiter (int): The maximum number of iterations to compute.\n",
    "\n",
    "    Returns:\n",
    "        ((n,) ndarray): The approximate minimum of f.\n",
    "        (bool): Whether or not the algorithm converged.\n",
    "        (int): The number of iterations computed.\n",
    "    \"\"\"\n",
    "    \n",
    "    converged = True\n",
    "   \n",
    "    ### Follow Algorithm 12.2 in the lab PDF\n",
    "    xk = x0\n",
    "    rk = -df(xk)\n",
    "    dk = rk\n",
    "    \n",
    "    line = lambda a: f(xk + a*dk)\n",
    "    ak = opt.minimize_scalar(line).x\n",
    "\n",
    "    xk = xk + ak*dk\n",
    "\n",
    "    k = 1\n",
    "    while np.linalg.norm(rk) >= tol:\n",
    "        if k >= maxiter:\n",
    "            converged = False\n",
    "            break\n",
    "        \n",
    "        rk1 = -df(xk)\n",
    "        bk = rk1@rk1 / (rk@rk)\n",
    "        dk = rk1 + bk*dk\n",
    "\n",
    "        line = lambda a: f(xk + a*dk)\n",
    "        ak = opt.minimize_scalar(line).x\n",
    "\n",
    "        xk = xk + ak*dk\n",
    "        \n",
    "        rk = rk1\n",
    "        k += 1\n",
    "    \n",
    "    return xk, converged, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.00000121, 1.00000242]), True, 119)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(t):\n",
    "    x,y = t\n",
    "    return 100*(y - x**2)**2 + (1 - x)**2\n",
    "def df(t):\n",
    "    x,y = t\n",
    "    return np.array([2*100*(y - x**2)*(-2)*x + 2*(1 - x)*(-1),\n",
    "                     2*100*(y - x**2)])\n",
    "\n",
    "x0 = np.array([2,2])\n",
    "nonlinear_conjugate_gradient(f, df, x0, maxiter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-3.69373570e-17, -9.18178140e-18, -1.13656354e-18]), True, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    Q = np.diag([1,2,3])\n",
    "    b = np.array([0,0,0])\n",
    "\n",
    "    return x@Q@x/2 - b@x\n",
    "def df(x):\n",
    "    b = np.array([0,0,0])\n",
    "    return x@Q - b\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "# f(x), Q@x\n",
    "x0 = np.array([1,2,3])\n",
    "nonlinear_conjugate_gradient(f, df, x0, maxiter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 44\n",
      "         Function evaluations: 102\n",
      "         Gradient evaluations: 102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.00000007, 1.00000015])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.fmin_cg(opt.rosen, np.array([10, 10]), fprime=opt.rosen_der)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.48225800e+06,  1.50163079e+01, -3.58158119e-02, -2.02018899e+00,\n",
       "       -1.03316876e+00, -5.10969536e-02,  1.82915214e+03])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem 4\n",
    "def prob4(filename='linregression.txt',\n",
    "          x0=np.array([-3482258, 15, 0, -2, -1, 0, 1829])):\n",
    "    \"\"\"Use conjugate_gradient() to solve the linear regression problem with\n",
    "    the data from the given file, the given initial guess, and the default\n",
    "    tolerance. Return the solution to the corresponding Normal Equations.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    # Each row: y, x1, ..., xn\n",
    "    A = np.loadtxt(filename)\n",
    "\n",
    "    # Get vector of y\n",
    "    b = A[:, 0].copy()\n",
    "\n",
    "    # Set first column to 1\n",
    "    # Each row: 1, x1, ..., xn\n",
    "    A[:, 0] = 1\n",
    "\n",
    "    # Get Q = A^T A to solve normal eqn A^T A x = A^T b\n",
    "    Q = A.T@A\n",
    "    ATb = A.T@b\n",
    "\n",
    "    return conjugate_gradient(Q, ATb, x0)[0]\n",
    "    \n",
    "prob4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 5\n",
    "class LogisticRegression1D:\n",
    "    \"\"\"Binary logistic regression classifier for one-dimensional data.\"\"\"\n",
    "\n",
    "    def fit(self, x, y, guess):\n",
    "        \"\"\"Choose the optimal beta values by minimizing the negative log\n",
    "        likelihood function, given data and outcome labels.\n",
    "\n",
    "        Parameters:\n",
    "            x ((n,) ndarray): An array of n predictor variables.\n",
    "            y ((n,) ndarray): An array of n outcome variables.\n",
    "            guess (array): Initial guess for beta.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define negative log likelihood function\n",
    "        def NLL(b):\n",
    "            b0, b1 = b\n",
    "            return np.sum(np.log(1 + np.exp(-(b0 + b1*x))) + (1-y)*(b0 + b1*x))\n",
    "        \n",
    "        # Save b0, b1 minimizing NLL\n",
    "        self.b0, self.b1 = opt.fmin_cg(NLL, guess, disp=False)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Calculate the probability of an unlabeled predictor variable\n",
    "        having an outcome of 1.\n",
    "\n",
    "        Parameters:\n",
    "            x (float): a predictor variable with an unknown label.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Return sigma(x)\n",
    "        return 1/(1 + np.exp(-(self.b0 + self.b1*x)))\n",
    "\n",
    "\n",
    "LogReg = LogisticRegression1D()\n",
    "    \n",
    "# x: ambient temp\n",
    "# y: 1 if O-ring damage present, 0 else\n",
    "data = np.load('challenger.npy').T\n",
    "\n",
    "LogReg.fit(data[0], data[1], np.array([20., -1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.999609671069125"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem 6\n",
    "def prob6(filename='challenger.npy', guess=np.array([20., -1.])):\n",
    "    \"\"\"Return the probability of O-ring damage at 31 degrees Farenheit.\n",
    "    Additionally, plot the logistic curve through the challenger data\n",
    "    on the interval [30, 100].\n",
    "\n",
    "    Parameters:\n",
    "        filename (str): The file to perform logistic regression on.\n",
    "                        Defaults to \"challenger.npy\"\n",
    "        guess (array): The initial guess for beta.\n",
    "                        Defaults to [20., -1.]\n",
    "    \"\"\"\n",
    "    \n",
    "    # x: ambient temp\n",
    "    # y: 1 if O-ring damage present, 0 else\n",
    "    data = np.load(filename).T\n",
    "\n",
    "    # Fit logistic regression\n",
    "    LogReg = LogisticRegression1D()\n",
    "    LogReg.fit(data[0], data[1], guess)\n",
    "\n",
    "    # Prediction for 31 degrees F\n",
    "    x = 31\n",
    "    y = LogReg.predict(x)\n",
    "\n",
    "    # Plot\n",
    "    domain = np.linspace(30, 100, 200)\n",
    "    plt.plot(domain, LogReg.predict(domain), color='orange')\n",
    "    plt.scatter(data[0], data[1], label='Previous damage')\n",
    "    plt.scatter(x, y, label='P(damage) at launch', color='green')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return y\n",
    "\n",
    "prob6()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
